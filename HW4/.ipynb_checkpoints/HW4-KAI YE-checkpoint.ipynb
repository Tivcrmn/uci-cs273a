{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min is: 193.5\n",
      "max is: 253.0\n",
      "mean is: 241.6011037\n",
      "variance is: 83.49917114984629\n",
      "min is: 152.5\n",
      "max is: 249.0\n",
      "mean is: 227.37657129999997\n",
      "variance is: 92.6255931250163\n",
      "min is: 214.25\n",
      "max is: 252.5\n",
      "mean is: 241.55415050000002\n",
      "variance is: 35.28633980334975\n",
      "min is: 152.5\n",
      "max is: 252.5\n",
      "mean is: 232.82676815000002\n",
      "variance is: 97.62573174864559\n",
      "min is: 10.0\n",
      "max is: 31048.0\n",
      "mean is: 3089.923365\n",
      "variance is: 15651513.756432075\n",
      "min is: 0.0\n",
      "max is: 13630.0\n",
      "mean is: 928.25902\n",
      "variance is: 3081761.8169486397\n",
      "min is: 0.0\n",
      "max is: 9238.0\n",
      "mean is: 138.09383\n",
      "variance is: 443951.7464459313\n",
      "min is: 0.0\n",
      "max is: 125.17\n",
      "mean is: 3.2485793302999997\n",
      "variance is: 8.2194850249125\n",
      "min is: 0.87589\n",
      "max is: 19.167\n",
      "mean is: 6.498652902750002\n",
      "variance is: 6.405048191357353\n",
      "min is: 0.0\n",
      "max is: 13.23\n",
      "mean is: 2.09713912048\n",
      "variance is: 4.363440470613412\n",
      "min is: 0.0\n",
      "max is: 66.761\n",
      "mean is: 4.21766040935\n",
      "variance is: 4.086371884226909\n",
      "min is: 0.0\n",
      "max is: 73.902\n",
      "mean is: 2.6917184521500004\n",
      "variance is: 2.198778474358265\n",
      "min is: 0.99049\n",
      "max is: 975.04\n",
      "mean is: 10.2715904759\n",
      "variance is: 404.6462450411813\n",
      "min is: -999.9\n",
      "max is: 797.2\n",
      "mean is: 5.781480499999999\n",
      "variance is: 3406.52055097812\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "for i in range(X.shape[1]):\n",
    "    print(\"min is:\", np.min(X[:, i]))\n",
    "    print(\"max is:\", np.max(X[:, i]))\n",
    "    print(\"mean is:\",np.mean(X[:,i]))\n",
    "    print(\"variance is:\",np.var(X[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XtS's min is: -4.526139905860034\n",
      "XtS's max is: 1.2200737538531763\n",
      "XtS's mean is: -1.2701661944447551e-14\n",
      "XtS's variance is: 0.9999999999999989\n",
      "XtS's min is: -3.8234733576454047\n",
      "XtS's max is: 1.9142315558699168\n",
      "XtS's mean is: -1.0743406164692715e-15\n",
      "XtS's variance is: 1.0000000000000182\n",
      "XtS's min is: -4.315928237411408\n",
      "XtS's max is: 1.7930634245451242\n",
      "XtS's mean is: -1.0915357506746659e-14\n",
      "XtS's variance is: 1.0000000000000016\n",
      "XtS's min is: -2.74829255553163\n",
      "XtS's max is: 1.9678459501805547\n",
      "XtS's mean is: -6.63249011267908e-14\n",
      "XtS's variance is: 1.000000000000002\n",
      "XtS's min is: -0.776534733491354\n",
      "XtS's max is: 7.009579922314298\n",
      "XtS's mean is: -2.8776980798284056e-17\n",
      "XtS's variance is: 0.9999999999999963\n",
      "XtS's min is: -0.5276741504735705\n",
      "XtS's max is: 6.959997009665682\n",
      "XtS's mean is: -2.3092638912203255e-17\n",
      "XtS's variance is: 0.9999999999999666\n",
      "XtS's min is: -0.22157101695364612\n",
      "XtS's max is: 12.582094536038268\n",
      "XtS's mean is: 2.7000623958883807e-17\n",
      "XtS's variance is: 1.0\n",
      "XtS's min is: -1.1212122749257782\n",
      "XtS's max is: 7.794709770326809\n",
      "XtS's mean is: -1.2001066806988092e-15\n",
      "XtS's variance is: 0.9999999999999983\n",
      "XtS's min is: -2.100653810793368\n",
      "XtS's max is: 4.0050759368922\n",
      "XtS's mean is: -3.0027536013221832e-15\n",
      "XtS's variance is: 0.9999999999999946\n",
      "XtS's min is: -0.9927671048201044\n",
      "XtS's max is: 4.343948594701857\n",
      "XtS's mean is: -6.018296971888048e-16\n",
      "XtS's variance is: 0.9999999999999963\n",
      "XtS's min is: -2.1098461351287985\n",
      "XtS's max is: 6.32800694578864\n",
      "XtS's mean is: -5.300648808770347e-15\n",
      "XtS's variance is: 0.9999999999999977\n",
      "XtS's min is: -1.9427750557317403\n",
      "XtS's max is: 9.85730266786242\n",
      "XtS's mean is: -8.029132914089132e-17\n",
      "XtS's variance is: 0.9999999999999986\n",
      "XtS's min is: -0.5667790732902931\n",
      "XtS's max is: 29.222134060361565\n",
      "XtS's mean is: -1.06368247543287e-15\n",
      "XtS's variance is: 1.000000000000023\n",
      "XtS's min is: -17.204979481473227\n",
      "XtS's max is: 12.460273360883429\n",
      "XtS's mean is: 1.5631940186722203e-16\n",
      "XtS's variance is: 0.9999999999999575\n",
      "XvS's min is: -4.738962633997559\n",
      "XvS's max is: 1.2200737538531763\n",
      "XvS's mean is: 0.0052767267214291255\n",
      "XvS's variance is: 0.9367375855545972\n",
      "XvS's min is: -7.665686469374415\n",
      "XvS's max is: 2.2216086048082375\n",
      "XvS's mean is: 0.019339139329034943\n",
      "XvS's variance is: 0.9721138064751224\n",
      "XvS's min is: -4.315928237411408\n",
      "XvS's max is: 1.8127645532587715\n",
      "XvS's mean is: 0.03161472959892276\n",
      "XvS's variance is: 0.9242338163552176\n",
      "XvS's min is: -8.062986970401493\n",
      "XvS's max is: 1.9798974114387635\n",
      "XvS's mean is: 0.01228104159511084\n",
      "XvS's variance is: 0.9821672058883582\n",
      "XvS's min is: -0.7757821125360951\n",
      "XvS's max is: 7.009579922314298\n",
      "XvS's mean is: 0.002686154364049537\n",
      "XvS's variance is: 1.0262217284750166\n",
      "XvS's min is: -0.5276741504735705\n",
      "XvS's max is: 6.959997009665682\n",
      "XvS's mean is: -0.01646452639811459\n",
      "XvS's variance is: 0.9289108775172769\n",
      "XvS's min is: -0.22157101695364612\n",
      "XvS's max is: 13.266884038188252\n",
      "XvS's mean is: -0.024332950983432612\n",
      "XvS's variance is: 1.0264479316212134\n",
      "XvS's min is: -1.1212122749257782\n",
      "XvS's max is: 41.372256194185375\n",
      "XvS's mean is: -0.006320447335277704\n",
      "XvS's variance is: 1.293279063425003\n",
      "XvS's min is: -2.1886408504759713\n",
      "XvS's max is: 4.030247177503832\n",
      "XvS's mean is: -0.02367484598426146\n",
      "XvS's variance is: 0.9360964950326357\n",
      "XvS's min is: -0.9927671048201044\n",
      "XvS's max is: 4.291839565616095\n",
      "XvS's mean is: -0.022329384644359733\n",
      "XvS's variance is: 0.9466897717707765\n",
      "XvS's min is: -2.1098461351287985\n",
      "XvS's max is: 7.426620710244957\n",
      "XvS's mean is: 0.004012019616494432\n",
      "XvS's variance is: 1.0805267897835886\n",
      "XvS's min is: -1.9427750557317403\n",
      "XvS's max is: 13.414715874484203\n",
      "XvS's mean is: -0.013239881858134283\n",
      "XvS's variance is: 1.0943664814352352\n",
      "XvS's min is: -0.5610247046764084\n",
      "XvS's max is: 29.222134060361565\n",
      "XvS's mean is: 0.016700952279187893\n",
      "XvS's variance is: 1.1582231743804363\n",
      "XvS's min is: -17.204979481473227\n",
      "XvS's max is: 7.818399032775636\n",
      "XvS's mean is: 0.012249761026161004\n",
      "XvS's variance is: 0.7341351390893809\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "for i in range(XtS.shape[1]):\n",
    "    print(\"XtS's min is:\", np.min(XtS[:, i]))\n",
    "    print(\"XtS's max is:\", np.max(XtS[:, i]))\n",
    "    print(\"XtS's mean is:\",np.mean(XtS[:,i]))\n",
    "    print(\"XtS's variance is:\",np.var(XtS[:,i]))\n",
    "for i in range(XvS.shape[1]):\n",
    "    print(\"XvS's min is:\", np.min(XvS[:, i]))\n",
    "    print(\"XvS's max is:\", np.max(XvS[:, i]))\n",
    "    print(\"XvS's mean is:\",np.mean(XvS[:,i]))\n",
    "    print(\"XvS's variance is:\",np.var(XvS[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "regcollection=[0.0,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0]\n",
    "auccollection=[]\n",
    "learner = ml.linearC.linearClassify()\n",
    "for x in regcollection:\n",
    "    learner.train(XtS, Yt, x, initStep=0.1, stopTol=1e-6, stopIter=100)\n",
    "    auccollection.append(learner.auc(XtS, Yt))# training AUC   \n",
    "plt.plot(regcollection,auccollection) \n",
    "plt.xlabel('reg')\n",
    "plt.ylabel('TrainingAUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "regcollection=[0.0,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0]\n",
    "auccollection=[]\n",
    "learner = ml.linearC.linearClassify()\n",
    "for x in regcollection:\n",
    "    learner.train(XtS, Yt, x, initStep=0.1, stopTol=1e-6, stopIter=100)\n",
    "    auccollection.append(learner.auc(XvS, Yv))# validation AUC\n",
    "plt.plot(regcollection,auccollection) \n",
    "plt.xlabel('reg')\n",
    "plt.ylabel('ValidationAUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.transforms as xform\n",
    "X = np.genfromtxt('X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "Xt2 = xform.fpoly(XtS,2, bias=False)\n",
    "print (Xt2.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of features is 119 because it consists of 14 original data and 14 x1*x1, x2*x2...x14*x14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also other 14*13/2=91 polynomials such as : x1*x2 x2*x3..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.transforms as xform\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "Xt2 = xform.fpoly(Xt,2, bias=False)\n",
    "Xv2 = xform.fpoly(Xv,2, bias=False)\n",
    "\n",
    "Xt2S, params = ml.transforms.rescale(Xt2)\n",
    "Xv2S, _ = ml.rescale(Xv2, params)\n",
    "regcollection=[0.0,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0]\n",
    "trainingauccollection=[]\n",
    "validationauccollection=[]\n",
    "learner = ml.linearC.linearClassify()\n",
    "for x in regcollection:\n",
    "    learner.train(Xt2S, Yt, x, initStep=0.1, stopTol=1e-6, stopIter=100)\n",
    "    trainingauccollection.append(learner.auc(Xt2S, Yt))\n",
    "plt.plot(regcollection,trainingauccollection) # training AUC\n",
    "plt.xlabel('reg')\n",
    "plt.ylabel('TrainingAUC')\n",
    "plt.show()\n",
    "for x in regcollection:\n",
    "    learner.train(Xt2S, Yt, x, initStep=0.1, stopTol=1e-6, stopIter=100)\n",
    "    validationauccollection.append(learner.auc(Xv2S, Yt))\n",
    "plt.plot(regcollection,validationauccollection) # validation AUC\n",
    "plt.xlabel('reg')\n",
    "plt.ylabel('ValidationAUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.transforms as xform\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "kcollection=[1,3,5,7,9,11,13]\n",
    "TrainingAUC=[]\n",
    "ValidationAUC=[]\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "learner = ml.knn.knnClassify()\n",
    "for k in kcollection:\n",
    "    learner.train(XtS, Yt,k, alpha=0.0)\n",
    "    TrainingAUC.append(learner.auc(XtS, Yt)) # train AUC\n",
    "    ValidationAUC.append(learner.auc(XvS,Yv))\n",
    "plt.plot(kcollection,TrainingAUC)\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('TrainingAUC')\n",
    "plt.show()\n",
    "plt.plot(kcollection,ValidationAUC)\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('ValidationAUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.transforms as xform\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "kcollection=[1,3,5,7,9,11,13]\n",
    "TrainingAUC=[]\n",
    "ValidationAUC=[]\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "learner = ml.knn.knnClassify()\n",
    "for k in kcollection:\n",
    "    learner.train(Xt, Yt,k, alpha=0.0)\n",
    "    TrainingAUC.append(learner.auc(Xt, Yt)) # train AUC\n",
    "    ValidationAUC.append(learner.auc(Xv,Yv))\n",
    "plt.plot(kcollection,TrainingAUC)\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('TrainingAUC')\n",
    "plt.show()\n",
    "plt.plot(kcollection,ValidationAUC)\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('ValidationAUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.transforms as xform\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "kcollection=[1,3,5,7,9,11,13]\n",
    "TrainingAUC=[]\n",
    "ValidationAUC=[]\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "K = range(1,25,5) # Or something else\n",
    "A = range(0,5,1) # Or something else\n",
    "tr_auc = np.zeros((len(K),len(A)))\n",
    "va_auc = np.zeros((len(K),len(A)))\n",
    "for i,k in enumerate(K):\n",
    "    for j,a in enumerate(A):\n",
    "        learner.train(XtS, Yt,k,a)\n",
    "        tr_auc[i][j] =learner.auc(XtS,Yt) \n",
    "        va_auc[i][j] =learner.auc(XvS,Yv)\n",
    "# Now plot it\n",
    "f, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "cax = ax.matshow(tr_auc, interpolation='nearest')\n",
    "f.colorbar(cax)\n",
    "ax.set_xticklabels(['']+list(A))\n",
    "ax.set_yticklabels(['']+list(K))\n",
    "plt.show()\n",
    "\n",
    "ff, axx = plt.subplots(1, 1, figsize=(8, 5))\n",
    "caxx = axx.matshow(va_auc, interpolation='nearest')\n",
    "ff.colorbar(caxx)\n",
    "axx.set_xticklabels(['']+list(A))\n",
    "axx.set_yticklabels(['']+list(K))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I would recommand K=21 and alpha=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "maxdepthcollection=[1,5,10,15,20,25,30]\n",
    "TrainingAUC=[]\n",
    "ValidationAUC=[]\n",
    "for x in maxdepthcollection:\n",
    "    learner = ml.dtree.treeClassify(XtS,Yt,maxDepth=x)\n",
    "    TrainingAUC.append(learner.auc(XtS,Yt))\n",
    "    ValidationAUC.append(learner.auc(XvS,Yv))\n",
    "plt.plot(maxdepthcollection,TrainingAUC)\n",
    "plt.xlabel('maxDepth')\n",
    "plt.ylabel('TrainingAUC')\n",
    "plt.show()\n",
    "plt.plot(maxdepthcollection,ValidationAUC)\n",
    "plt.xlabel('maxDepth')\n",
    "plt.ylabel('ValidationAUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.transforms as xform\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "maxdepthcollection=[1,5,10,15,20,25,30]\n",
    "nodecollection=[]\n",
    "nodecollection2=[]\n",
    "count=2\n",
    "for x in maxdepthcollection:\n",
    "    learner = ml.dtree.treeClassify(XtS,Yt,maxDepth=x)\n",
    "    nodecollection.append(learner.sz)\n",
    "    learner1=ml.dtree.treeClassify(XtS,Yt,maxDepth=x,minLeaf=count)\n",
    "    nodecollection2.append(learner1.sz)\n",
    "    count=count+1\n",
    "plt.plot(maxdepthcollection,nodecollection)\n",
    "plt.plot(maxdepthcollection,nodecollection2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.transforms as xform\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "\n",
    "Par = range(2,20,2) # Or something else\n",
    "L = range(1,10,1) # Or something else\n",
    "tr_auc = np.zeros((len(Par),len(L)))\n",
    "va_auc = np.zeros((len(Par),len(L)))\n",
    "for i,k in enumerate(Par):\n",
    "    for j,a in enumerate(L):\n",
    "        learner = ml.dtree.treeClassify(XtS, Yt, maxDepth=15,minParent=k,minLeaf=a)\n",
    "        tr_auc[i][j] = learner.auc(XtS,Yt) # train learner using k and a\n",
    "        va_auc[i][j] = learner.auc(XvS,Yv)\n",
    "f, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "cax = ax.matshow(tr_auc, interpolation='nearest')\n",
    "f.colorbar(cax)\n",
    "ax.set_xticklabels(['']+list(L))\n",
    "ax.set_yticklabels(['']+list(Par))\n",
    "plt.show()\n",
    "ff, axx = plt.subplots(1, 1, figsize=(8, 5))\n",
    "caxx = axx.matshow(va_auc, interpolation='nearest')\n",
    "ff.colorbar(caxx)\n",
    "axx.set_xticklabels(['']+list(L))\n",
    "axx.set_yticklabels(['']+list(Par))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I would recommand minParent=18 and minLeaf=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.transforms as xform\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "\n",
    "nn = ml.nnet.nnetClassify()\n",
    "\n",
    "L=range(1,6,1)                \n",
    "Nodes = range(1,10,1) # Or something else\n",
    "tr_auc = np.zeros((len(L),len(Nodes)))\n",
    "va_auc = np.zeros((len(L),len(Nodes)))\n",
    "for j,n in enumerate(Nodes):\n",
    "    nn.init_weights([XtS.shape[1], n,2], 'random', XtS, Yt) # as many layers nodes you want\n",
    "    nn.train(XtS, Yt, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "    tr_auc[0][j] = nn.auc(XtS,Yt) # train learner using k and a\n",
    "    va_auc[0][j] = nn.auc(XvS,Yv)\n",
    "for j,n in enumerate(Nodes):\n",
    "    nn.init_weights([XtS.shape[1], n,n,2], 'random', XtS, Yt) # as many layers nodes you want\n",
    "    nn.train(XtS, Yt, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "    tr_auc[1][j] = nn.auc(XtS,Yt) # train learner using k and a\n",
    "    va_auc[1][j] = nn.auc(XvS,Yv)\n",
    "for j,n in enumerate(Nodes):\n",
    "    nn.init_weights([XtS.shape[1], n,n,n,2], 'random', XtS, Yt) # as many layers nodes you want\n",
    "    nn.train(XtS, Yt, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "    tr_auc[2][j] = nn.auc(XtS,Yt) # train learner using k and a\n",
    "    va_auc[2][j] = nn.auc(XvS,Yv)\n",
    "for j,n in enumerate(Nodes):\n",
    "    nn.init_weights([XtS.shape[1], n,n,n,n,2], 'random', XtS, Yt) # as many layers nodes you want\n",
    "    nn.train(XtS, Yt, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "    tr_auc[3][j] = nn.auc(XtS,Yt) # train learner using k and a\n",
    "    va_auc[3][j] = nn.auc(XvS,Yv)\n",
    "for j,n in enumerate(Nodes):\n",
    "    nn.init_weights([XtS.shape[1], n,n,n,n,n,2], 'random', XtS, Yt) # as many layers nodes you want\n",
    "    nn.train(XtS, Yt, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "    tr_auc[4][j] = nn.auc(XtS,Yt) \n",
    "    va_auc[4][j] = nn.auc(XvS,Yv)\n",
    "f, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "cax = ax.matshow(tr_auc, interpolation='nearest')\n",
    "f.colorbar(cax)\n",
    "ax.set_xticklabels(['']+list(Nodes))\n",
    "ax.set_yticklabels(['']+list(L))\n",
    "ax.set_title('TrainingAUC')\n",
    "plt.show()\n",
    "ff, axx = plt.subplots(1, 1, figsize=(8, 5))\n",
    "caxx = axx.matshow(va_auc, interpolation='nearest')\n",
    "ff.colorbar(caxx)\n",
    "axx.set_xticklabels(['']+list(Nodes))\n",
    "axx.set_yticklabels(['']+list(L))\n",
    "axx.set_title('ValidationAUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I would recommand number of hidden layers=2 and nodes in each layer=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.transforms as xform\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y,0.75)\n",
    "Xt, Yt = Xtr[:5000], Ytr[:5000]\n",
    "Xv, Yv = Xva[:5000], Yva[:5000]\n",
    "XtS, params = ml.transforms.rescale(Xt)\n",
    "XvS, _ = ml.rescale(Xv, params)\n",
    "\n",
    "nn = ml.nnet.nnetClassify()\n",
    "tr_auc = np.zeros((len(L),len(Nodes)))\n",
    "va_auc = np.zeros((len(L),len(Nodes)))\n",
    "nn.init_weights([XtS.shape[1],8,8,2], 'random', XtS, Yt)\n",
    "sig = lambda z: np.atleast_2d(z)\n",
    "dsig = lambda z: np.atleast_2d(1)\n",
    "nn.setActivation('custom', sig, dsig)\n",
    "nn.train(XtS, Yt, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "print(\"Custom activation TrianAUC:\",nn.auc(XtS,Yt))\n",
    "print(\"Custom activation ValidateAUC:\",nn.auc(XvS,Yv))\n",
    "\n",
    "nn = ml.nnet.nnetClassify()\n",
    "nn.init_weights([XtS.shape[1],8,8,2], 'random', XtS, Yt)\n",
    "nn.setActivation('Logistic', sig, dsig)\n",
    "nn.train(XtS, Yt, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "print(\"Logistic activation TrianAUC:\",nn.auc(XtS,Yt))\n",
    "print(\"Logistic activation ValidateAUC:\",nn.auc(XvS,Yv))\n",
    "                 \n",
    "nn = ml.nnet.nnetClassify()\n",
    "nn.init_weights([XtS.shape[1],8,8,2], 'random', XtS, Yt)\n",
    "nn.setActivation('Htangent', sig, dsig)\n",
    "nn.train(XtS, Yt, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "print(\"Htangent activation TrianAUC:\",nn.auc(XtS,Yt))\n",
    "print(\"Htangent activation ValidateAUC:\",nn.auc(XvS,Yv))             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our custom activation is better than logistic activation, but worse than Htangent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prefer linear classifier to others because it will not easily overfit and using gradient descent we can get quite "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good parameters which gives us accurate predictions. My username is KAI YE, the leaderboard score is 0.54683."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ml.linearC.linearClassify()\n",
    "learner.train(XtS, Y, 4, initStep=1e-6, stopTol=1e-6, stopIter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement of Collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No disscussion with others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
